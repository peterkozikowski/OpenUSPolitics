name: Daily Bill Analysis Pipeline

on:
  # Run daily at 2 AM UTC
  schedule:
    - cron: '0 2 * * *'

  # Allow manual triggering from Actions tab
  workflow_dispatch:
    inputs:
      bill_count:
        description: 'Number of bills to analyze'
        required: false
        default: '10'
        type: string

# Only run one analysis at a time
concurrency:
  group: bill-analysis-pipeline
  cancel-in-progress: false

jobs:
  analyze:
    name: Fetch and Analyze Bills
    runs-on: ubuntu-latest

    # Set timeout to prevent long-running jobs (2 hours max)
    timeout-minutes: 120

    # Required permissions for committing changes
    permissions:
      contents: write

    steps:
      # Step 1: Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git operations
          token: ${{ secrets.GITHUB_TOKEN }}

      # Step 2: Setup Python environment
      - name: Setup Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'  # Cache pip dependencies
          cache-dependency-path: 'pipeline/requirements.txt'

      # Step 3: Install Python dependencies
      - name: Install pipeline dependencies
        run: |
          cd pipeline
          pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Create .env file with secrets
      - name: Configure environment
        run: |
          cd pipeline
          cat > .env << EOF
          CONGRESS_GOV_API_KEY=${{ secrets.CONGRESS_GOV_API_KEY }}
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          BILLS_FETCH_LIMIT=${{ github.event.inputs.bill_count || '10' }}
          GIT_AUTO_COMMIT=false
          LOG_LEVEL=INFO
          EOF

      # Step 5: Run the ETL pipeline
      - name: Run bill analysis pipeline
        run: |
          cd pipeline
          python main.py \
            --bills ${{ github.event.inputs.bill_count || '10' }} \
            --verbose
        env:
          PYTHONUNBUFFERED: 1  # Ensure real-time log output

      # Step 6: Check for changes in data
      - name: Check for data changes
        id: check_changes
        run: |
          cd pipeline
          if [[ -n $(git status --porcelain .) ]]; then
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "âœ“ New bill analyses detected"
          else
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "âœ— No new analyses to commit"
          fi

      # Step 7: Commit and push updated data
      - name: Commit updated bill data
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          cd pipeline

          # Configure git
          git config user.name "OpenUSPolitics Bot"
          git config user.email "bot@openuspolitics.org"

          # Add all data files (from repo root perspective)
          git add .

          # Create commit with timestamp and bill count
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M UTC")
          BILL_COUNT=$(ls data/bills/*.json 2>/dev/null | wc -l)

          git commit -m "Update bill analyses - $TIMESTAMP

          - Analyzed ${{ github.event.inputs.bill_count || '10' }} bills
          - Total bills in database: $BILL_COUNT
          - Automated update via GitHub Actions

          ðŸ¤– Generated by OpenUSPolitics.org ETL Pipeline"

          # Push changes
          git push

      # Step 8: Trigger Cloudflare Pages rebuild
      # This ensures the website shows the latest data
      - name: Trigger Cloudflare Pages rebuild
        if: steps.check_changes.outputs.changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.repos.createDispatchEvent({
              owner: context.repo.owner,
              repo: context.repo.repo,
              event_type: 'rebuild-site'
            });

      # Step 9: Generate summary report
      - name: Generate job summary
        if: always()
        run: |
          cd pipeline

          BILL_COUNT=$(ls data/bills/*.json 2>/dev/null | wc -l || echo "0")

          cat >> $GITHUB_STEP_SUMMARY << EOF
          # ðŸ“Š Bill Analysis Pipeline Report

          ## Summary
          - **Date**: $(date -u +"%Y-%m-%d %H:%M UTC")
          - **Bills Requested**: ${{ github.event.inputs.bill_count || '10' }}
          - **Total Bills in Database**: $BILL_COUNT
          - **Status**: ${{ job.status }}
          - **Changes Committed**: ${{ steps.check_changes.outputs.changes || 'N/A' }}

          ## Pipeline Steps
          - âœ“ Fetch bills from Congress.gov API
          - âœ“ Parse and chunk bill text
          - âœ“ Generate embeddings
          - âœ“ Analyze with Claude AI
          - âœ“ Audit for bias
          - âœ“ Save to repository

          ## Next Steps
          - Data is now available in \`pipeline/data/bills/\`
          - Cloudflare Pages will rebuild automatically
          - New analyses will be visible on openuspolitics.org
          EOF

      # Step 10: Upload logs as artifacts (for debugging)
      - name: Upload pipeline logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: |
            pipeline/logs/*.log
            pipeline/logs/*.json
            pipeline/data/bills/metadata.json
          retention-days: 30

      # Step 11: Notify on failure
      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Bill analysis pipeline failed! Check logs for details."
          echo "Failed at: $(date -u)"

          # You can add additional notification logic here
          # For example, sending to Slack, Discord, email, etc.
